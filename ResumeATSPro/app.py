# Import necessary libraries
import streamlit as st  # For building the web interface
import google.generativeai as genai  # Google's Generative AI library for interacting with Gemini models
import os  # To interact with the operating system (e.g., reading environment variables)
import PyPDF2 as pdf  # To extract text from PDF files
from dotenv import load_dotenv  # To load environment variables from a .env file
import json  # For handling JSON data (not directly used in this code)

# Load environment variables from the .env file
load_dotenv()

# Configure the Gemini API using the API key from the environment variables
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

## Function to interact with the Gemini Pro model and get responses
def get_gemini_repsonse(input):
    """
    This function sends input to the Gemini Pro model and retrieves the generated response.
    
    Parameters:
    - input: The input prompt or query provided by the user.
    
    Returns:
    - The response text generated by the Gemini Pro model.
    """
    model = genai.GenerativeModel('gemini-1.5-pro')  # Load the Gemini Pro model
    response = model.generate_content(input)  # Generate content based on the input
    return response.text  # Return the generated response as text

## Function to extract text from an uploaded PDF file
def input_pdf_text(uploaded_file):
    """
    This function reads a PDF file and extracts its text content.
    
    Parameters:
    - uploaded_file: The uploaded PDF file.
    
    Returns:
    - The extracted text from the PDF file.
    """
    reader = pdf.PdfReader(uploaded_file)  # Create a PDF reader object
    text = ""  # Initialize an empty string to store the extracted text
    for page in range(len(reader.pages)):  # Iterate through all pages in the PDF
        page_obj = reader.pages[page]  # Get the current page
        text += str(page_obj.extract_text())  # Extract text from the page and append it to the string
    return text  # Return the extracted text

# Define the prompt template for the Gemini model
input_prompt = """
Hey Act Like a skilled or very experienced ATS (Application Tracking System)
with a deep understanding of the tech field, software engineering, data science, 
data analyst, and big data engineer. Your task is to evaluate the resume based on 
the given job description. You must consider that the job market is very competitive 
and you should provide the best assistance for improving the resumes. Assign the 
percentage match based on the job description (JD) and identify the missing keywords 
with high accuracy.

Resume: {text}
Job Description: {jd}

I want the response in one single string having the structure:
{{"JD Match":"%", "MissingKeywords":[], "Profile Summary":""}}
"""

## Streamlit app
st.title("Smart ATS")  # Set the title of the Streamlit app
st.text("Improve Your Resume ATS")  # Display a brief description of the app

# Create a text area for the user to paste the job description
jd = st.text_area("Paste the Job Description")

# Allow the user to upload their resume in PDF format
uploaded_file = st.file_uploader("Upload Your Resume", type="pdf", help="Please upload the PDF file")

# Create a button for the user to submit their inputs
submit = st.button("Submit")

# If the "Submit" button is clicked
if submit:
    if uploaded_file is not None:  # Check if a file has been uploaded
        text = input_pdf_text(uploaded_file)  # Extract text from the uploaded PDF resume
        # Format the input prompt with the extracted resume text and job description
        formatted_prompt = input_prompt.format(text=text, jd=jd)
        # Get the response from the Gemini Pro model
        response = get_gemini_repsonse(formatted_prompt)
        # Display the response in the Streamlit app
        st.subheader(response)