# Import necessary libraries
from dotenv import load_dotenv  # To load environment variables from a .env file
import streamlit as st  # For building the web interface
import os  # To interact with the operating system (e.g., reading environment variables)
import pathlib  # For handling file paths (not directly used in this code)
import textwrap  # For formatting text (not directly used in this code)
from PIL import Image  # To handle image processing

import google.generativeai as genai  # Google's Generative AI library for interacting with Gemini models

# Load environment variables from the .env file
load_dotenv()

# Retrieve the Google API key from the environment variables and configure the Gemini API
os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

## Function to interact with the Gemini model and get responses
def get_gemini_response(input, image, prompt):
    """
    This function sends a prompt, an image, and additional input to the Gemini Pro Vision model
    and returns the model's response.
    
    Parameters:
    - input: Text input provided by the user.
    - image: The image data to be processed by the model.
    - prompt: A predefined instruction or context for the model.
    
    Returns:
    - The response text generated by the Gemini model.
    """
    model = genai.GenerativeModel('gemini-1.5-pro')  # Load the Gemini Pro Vision model
    response = model.generate_content([input, image[0], prompt])  # Generate content based on the inputs
    return response.text  # Return the generated response as text

## Function to process the uploaded image
def input_image_setup(uploaded_file):
    """
    This function processes the uploaded image file and prepares it for the Gemini model.
    
    Parameters:
    - uploaded_file: The file uploaded by the user via Streamlit's file uploader.
    
    Returns:
    - A list containing a dictionary with the image's MIME type and binary data.
    
    Raises:
    - FileNotFoundError if no file is uploaded.
    """
    if uploaded_file is not None:  # Check if a file has been uploaded
        bytes_data = uploaded_file.getvalue()  # Read the file into bytes
        image_parts = [
            {
                "mime_type": uploaded_file.type,  # Get the MIME type of the uploaded file (e.g., image/jpeg)
                "data": bytes_data  # Store the binary data of the image
            }
        ]
        return image_parts  # Return the prepared image data
    else:
        raise FileNotFoundError("No file uploaded")  # Raise an error if no file is uploaded

## Initialize the Streamlit app
st.set_page_config(page_title="Gemini Image Demo")  # Set the page title for the Streamlit app
st.header("Gemini Application")  # Display a header for the app

# Create a text input field for the user to provide a prompt
input = st.text_input("Input Prompt: ", key="input")

# Allow the user to upload an image file (only JPG, JPEG, or PNG formats are accepted)
uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

image = ""  # Initialize an empty variable to store the uploaded image
if uploaded_file is not None:  # If an image is uploaded
    image = Image.open(uploaded_file)  # Open the image using PIL
    st.image(image, caption="Uploaded Image.", use_column_width=True)  # Display the uploaded image

# Create a button for the user to submit their request
submit = st.button("Tell me about the image")

# Define a predefined prompt for the Gemini model
input_prompt = """
               You are an expert in understanding invoices.
               You will receive input images as invoices &
               you will have to answer questions based on the input image
               """

## If the "Tell me about the image" button is clicked
if submit:
    image_data = input_image_setup(uploaded_file)  # Process the uploaded image
    response = get_gemini_response(input_prompt, image_data, input)  # Get the Gemini model's response
    st.subheader("The Response is")  # Display a subheader for the response
    st.write(response)  # Display the model's response